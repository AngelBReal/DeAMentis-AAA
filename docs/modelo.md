# Proceso de Modelado

Este proyecto explor贸 diversas estrategias de clasificaci贸n de noticias con el objetivo de construir un modelo efectivo, trazable y explicable. A continuaci贸n se describe el flujo completo de experimentaci贸n, desde pruebas iniciales hasta la selecci贸n final del modelo.

---

## 1. Infraestructura de Experimentaci贸n

Todos los modelos fueron entrenados en **Google Colab**, aprovechando cr茅ditos gratuitos para ejecuci贸n de GPU/CPU intensiva. Cada experimento fue registrado usando **MLflow**, con artefactos sincronizados en **DagsHub**, lo que permite una trazabilidad total del proceso de modelado.

-  Visualizaci贸n completa de experimentos: [MLflow en DagsHub](https://dagshub.com/AngelBReal/DeAMentis-AAA.mlflow)

---

## 2. Fases de Experimentaci贸n

### `00_`: Experimentos exploratorios

Experimentos iniciales con distintos modelos base (`SVM`, `RegLog`, `GradientBoosting`, etc.) y preprocesamiento textual b谩sico. El objetivo fue entender la sensibilidad del rendimiento ante distintas transformaciones de texto.

 Conclusi贸n: El preprocesamiento (stopwords, lematizaci贸n, ngramas) influye m谩s que el modelo en s铆. Esto motiv贸 la siguiente fase m谩s sistem谩tica.

---

### `01_`: Comparaci贸n estructurada de datasets y modelos

Se probaron combinaciones de modelos cl谩sicos (`Naive Bayes`, `SVM`, `AdaBoost`, `RandomForest`) con 5 variantes de preprocesamiento:

- Raw unigramas
- Raw bigramas
- Stopwords unigramas
- Stemmed bigramas
- Lematizado + unigramas / bigramas

#### Resultados (SVM con distintas variantes):

| Modelo                        | Preprocesamiento | N-grama  | F1-score | AUC     |
|------------------------------|------------------|----------|----------|---------|
| Bigram_lemmatized__SVM       | Lematizado       | Bigrama  | 0.647    | 0.228   |
| Unigram_lemmatized__SVM      | Lematizado       | Unigrama | 0.632    | 0.236   |
| Unigram_stopwords__SVM       | Stopwords        | Unigrama | 0.600    | 0.268   |
| Unigram_raw__SVM             | Raw              | Unigrama | 0.600    | 0.262   |
| Unigram_stemmed__SVM         | Stemmed          | Unigrama | 0.600    | 0.276   |

Conclusi贸n: SVM combinado con lematizaci贸n y unigramas obtuvo los mejores resultados.

---

### `01 Best Dataset Calibrado V2`

Aqu铆 se desarroll贸 el **Voting Ensemble** (SVM + XGBoost) sobre el mejor dataset. Se compararon diferentes modelos:

#### Comparaci贸n de modelos calibrados

| Modelo            | Accuracy | F1-score | AUC     | Precisi贸n | Recall  |
|-------------------|----------|----------|---------|-----------|---------|
| Voting Ensemble   | 0.731    | 0.775    | 0.794   | 0.796     | 0.756   |
| XGBoost           | 0.693    | 0.743    | 0.764   | 0.762     | 0.726   |
| SVM Calibrado     | 0.729    | 0.665    | 0.786   | 0.637     | 0.696   |
| LightGBM          | 0.703    | 0.632    | 0.785   | 0.607     | 0.659   |

 El Voting Ensemble super贸 a todos los modelos individuales.

---

### `02 Optuna Ensemble Search`

Se aplic贸 **Optuna** para encontrar los hiperpar谩metros 贸ptimos del ensamble VotingClassifier.

#### Top combinaciones encontradas:

| svm_C   | xgb_estimators | xgb_lr  | F1-score | AUC     |
|---------|----------------|---------|----------|---------|
| 1.287   | 149            | 0.205   | 0.783    | 0.795   |
| 1.840   | 176            | 0.239   | 0.783    | 0.802   |
| 4.217   | 165            | 0.172   | 0.782    | 0.797   |
| 9.882   | 120            | 0.122   | 0.780    | 0.797   |
| 5.307   | 200            | 0.040   | 0.779    | 0.797   |

 El modelo con `svm_C = 1.287`, `xgb_lr = 0.205`, `xgb_estimators = 149` fue el elegido por su balance rendimiento/estabilidad.

---

## 3. Selecci贸n del Modelo Final

El modelo ganador fue el **VotingClassifier (SVM + XGBoost)** entrenado con:

- TF-IDF con unigramas
- Lematizaci贸n
- Selecci贸n de caracter铆sticas con `SelectKBest`
- Balanceo con `SMOTE`

Este modelo fue registrado como artefacto final en MLflow y es utilizado en producci贸n por el backend de FastAPI.

---

## 4. Alternativas probadas sin 茅xito

Tambi茅n se evaluaron modelos con **transformers** como **BETO**, pero no superaron al Voting Ensemble en F1-score ni en interpretabilidad, por lo cual se descartaron en esta fase.

---

## Trazabilidad completa

Todos los experimentos pueden ser visualizados y comparados desde:

 [MLflow UI en DagsHub](https://dagshub.com/AngelBReal/DeAMentis-AAA.mlflow)

Cada ejecuci贸n incluye:
- Hiperpar谩metros
- M茅tricas (F1, AUC, Precision, Recall)
- Artefactos (modelo, vectorizador, selector)
